{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom sklearn.metrics import classification_report\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np\nimport cv2\n\n# random\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# Using GPU for training\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Load data\nfile_path = ''\ndata = pd.read_csv(file_path)\n\n# Derive 'label' from the 'filename' column\ndata['label'] = data['filename'].apply(lambda x: 0 if 'benign' in x else 1)\n# Filter data for magnification (mag) == 40\ndata = data[data['mag'] == 40]\n\n# Parameters\ntarget_size = (224, 224)  # Target size for input\n\n# Dataset class\nclass BreastCancerDataset(Dataset):\n    def __init__(self, dataframe, target_size):\n        self.dataframe = dataframe\n        self.target_size = target_size\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        row = self.dataframe.iloc[idx]\n        img_path = row['filename']\n        img_path = '' + img_path\n        label = row['label']\n\n        img = cv2.imread(img_path)\n        if img is None:\n            raise FileNotFoundError(f\"Image not found: {img_path}\")\n\n        img = cv2.resize(img, self.target_size)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img / 255.0\n        img = np.transpose(img, (2, 0, 1))\n\n        img_tensor = torch.tensor(img, dtype=torch.float32)\n        label_tensor = torch.tensor(label, dtype=torch.long)\n\n        return img_tensor.reshape(-1), label_tensor\n\n# Split data into train and test\ntrain_df = data[data['grp'] == 'train']\ntest_df = data[data['grp'] == 'test']\n\n# validation size（use about 20% training dataset）\ntrain_size = int(0.8 * len(train_df))\nval_size = len(train_df) - train_size\n\n# Create datasets\ntrain_dataset = BreastCancerDataset(train_df.iloc[:train_size], target_size)\nval_dataset = BreastCancerDataset(train_df.iloc[train_size:], target_size)\ntest_dataset = BreastCancerDataset(test_df, target_size)\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# DNN nodel\nclass DNNModel(nn.Module):\n    def __init__(self, input_size, num_classes):\n        super(DNNModel, self).__init__()\n        self.fc1 = nn.Linear(input_size, 2048)\n        self.bn1 = nn.BatchNorm1d(2048)\n        self.fc2 = nn.Linear(2048, 1024)\n        self.bn2 = nn.BatchNorm1d(1024)\n        self.fc3 = nn.Linear(1024, 512)\n        self.bn3 = nn.BatchNorm1d(512)\n        self.fc4 = nn.Linear(512, 256)\n        self.bn4 = nn.BatchNorm1d(256)\n        self.fc5 = nn.Linear(256, num_classes)\n        \n        self.relu = nn.LeakyReLU(0.1)\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, x):\n        x = self.dropout(self.relu(self.bn1(self.fc1(x))))\n        x = self.dropout(self.relu(self.bn2(self.fc2(x))))\n        x = self.dropout(self.relu(self.bn3(self.fc3(x))))\n        x = self.dropout(self.relu(self.bn4(self.fc4(x))))\n        x = self.fc5(x)\n        return x\n\n# Initialize model\ninput_size = 3 * target_size[0] * target_size[1]\nnum_classes = len(data['label'].unique())\nmodel = DNNModel(input_size, num_classes)\nmodel = model.to(device)\n\n# calculate the class weight\ntotal_samples = len(train_df)\nnum_benign = len(train_df[train_df['label'] == 0])\nnum_malignant = len(train_df[train_df['label'] == 1])\n\nweight_benign = total_samples / (2 * num_benign)\nweight_malignant = total_samples / (2 * num_malignant)\nclass_weights = torch.tensor([weight_benign, weight_malignant]).to(device)\n\n# Loss function and optimizer\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\noptimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, \n    mode='min',\n    patience=3,  \n    factor=0.1,  \n    min_lr=1e-6\n)\n\n# define training model\ndef train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs):\n    best_val_loss = float('inf')\n    patience = 5\n    patience_counter = 0\n    \n    for epoch in range(epochs):\n        # Training phase\n        model.train()\n        running_loss = 0.0\n        train_correct = 0\n        train_total = 0\n        \n        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\"):\n            images, labels = images.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            train_total += labels.size(0)\n            train_correct += (predicted == labels).sum().item()\n        \n        train_loss = running_loss / len(train_loader)\n        train_acc = 100 * train_correct / train_total\n        \n        # Validation phase\n        model.eval()\n        val_loss = 0.0\n        val_correct = 0\n        val_total = 0\n        \n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                \n                _, predicted = torch.max(outputs.data, 1)\n                val_total += labels.size(0)\n                val_correct += (predicted == labels).sum().item()\n        \n        val_loss = val_loss / len(val_loader)\n        val_acc = 100 * val_correct / val_total\n        \n        # Print epoch results\n        print(f'Epoch [{epoch+1}/{epochs}]')\n        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n        \n        # Learning rate scheduling\n        scheduler.step(val_loss)\n        \n        # Early stopping\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            patience_counter = 0\n            # Save best model\n            torch.save(model.state_dict(), 'best_model.pth')\n        else:\n            patience_counter += 1\n            if patience_counter >= patience:\n                print(f'Early stopping triggered after epoch {epoch+1}')\n                break\n\n# Evaluation function\ndef evaluate_model(model, test_loader):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    test_loss = 0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            test_loss += loss.item()\n            \n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    test_loss = test_loss / len(test_loader)\n    accuracy = 100 * correct / total\n    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n    return all_labels, all_preds\n\n# Train the model\nepochs = 10\ntrain_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs)\n\n# Load best model and evaluate\nmodel.load_state_dict(torch.load('best_model.pth'))\ny_test, y_pred = evaluate_model(model, test_loader)\n\n# Print classification report\ntarget_names = ['Benign', 'Malignant']\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred, target_names=target_names))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}